{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Создать Dataset для загрузки данных (sklearn.datasets.fetch_california_housing)\n",
        "2. Обернуть его в Dataloader\n",
        "3. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
        "4. Сравните сходимость Adam, RMSprop и SGD, сделайте вывод по качеству работы модели train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
      ],
      "metadata": {
        "id": "huMEF6Ive4YK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8X3U3kN-fVXr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam, RMSprop, SGD\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CHDataset(Dataset):\n",
        "  def __init__(self, *init_datasets):\n",
        "    assert all(init_datasets[0].size(0) == init_dataset.size(0) for init_dataset in init_datasets), \"Несоотвутствует размерность среди dataset\"\n",
        "    self._base_datasets = init_datasets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._base_datasets[0].size(0)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      return tuple(base_dataset[idx] for base_dataset in self._base_datasets)"
      ],
      "metadata": {
        "id": "RKzTmboFCZIw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CHNet(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super(CHNet, self).__init__()\n",
        "      self.block_1 = nn.Sequential(\n",
        "          nn.Linear(in_features=8, out_features=100, bias=True),\n",
        "          # nn.Dropout(0.1),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.ReLU())\n",
        "      self.block_2 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=100, bias=True),\n",
        "          # nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(100),\n",
        "          nn.ReLU())\n",
        "      self.block_3 = nn.Sequential(\n",
        "          nn.Linear(in_features=100, out_features=60, bias=True),\n",
        "          # nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(60),\n",
        "          nn.ReLU())\n",
        "      self.block_4 = nn.Sequential(\n",
        "          nn.Linear(in_features=60, out_features=30),\n",
        "          # nn.Dropout(0.2),\n",
        "          nn.BatchNorm1d(30),\n",
        "          nn.ReLU())\n",
        "      self.predict = nn.Sequential(\n",
        "          nn.Linear(in_features=30, out_features=1, bias=True),\n",
        "          nn.BatchNorm1d(1),\n",
        "          nn.ReLU())\n",
        "\n",
        "  def forward(self, inp):\n",
        "    out = self.block_1(inp)\n",
        "    out = self.block_2(out)\n",
        "    out = self.block_3(out)\n",
        "    out = self.block_4(out)\n",
        "    out = self.predict(out)\n",
        "    return out[:, 0]"
      ],
      "metadata": {
        "id": "Ngvt0pKlC59C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHES = 10\n",
        "LR = 0.005"
      ],
      "metadata": {
        "id": "T0N6dzuyD5oz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(train_loader, test_loader, net, optimizer):\n",
        "  loss_fn = nn.MSELoss()\n",
        "  best_acc = {'train': None, 'test': None}\n",
        "  net.train()\n",
        "  for epoch in range(EPOCHES):\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(labels)\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 150 == 0 or (i + 1) == len(train_loader):    # печатаем каждые 150 mini-batches\n",
        "            net.eval()\n",
        "\n",
        "            test_loss, test_running_total, test_loss  = 0.0, 0.0, 0.0\n",
        "            for y, (out_test, lbl_test) in enumerate(test_loader):\n",
        "                test_outputs = net(out_test)\n",
        "                test_loss += loss_fn(test_outputs, lbl_test)\n",
        "                test_running_total += len(lbl_test)\n",
        "\n",
        "            res_loss_train = running_loss / running_items\n",
        "            res_loss_test = test_loss / test_running_total\n",
        "\n",
        "            if best_acc['train'] is None or res_loss_train < best_acc['train']:\n",
        "              best_acc['train'] = res_loss_train\n",
        "\n",
        "            if best_acc['test'] is None or res_loss_test < best_acc['test']:\n",
        "              best_acc['test'] = res_loss_train\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{EPOCHES}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {res_loss_train:.3f}. '\\\n",
        "                  f'Test acc: {res_loss_test:.3f}.')\n",
        "\n",
        "            running_loss, running_items = 0.0, 0.0\n",
        "            net.train()\n",
        "  print(f\"Best acc train: {best_acc['train']:.3f}. Best acc test: {best_acc['test']:.3f}\")\n",
        "  print('Training is finished!')"
      ],
      "metadata": {
        "id": "KRloT41HDOn3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california_housing = fetch_california_housing()\n",
        "# Разделим на тестовые и тренеровочные данные\n",
        "X_train, X_test, y_train, y_test = train_test_split(california_housing.data, california_housing.target, test_size=0.25, random_state=13)"
      ],
      "metadata": {
        "id": "i12QiNaSD9sZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализуем данные и подготовим их для дальнейшего использования в нашем dstaset\n",
        "scale = StandardScaler()\n",
        "X_train_s = scale.fit_transform(X_train)\n",
        "X_test_s = scale.transform(X_test)"
      ],
      "metadata": {
        "id": "U1PCy7JEEHBe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_xt = torch.from_numpy(X_train_s.astype(np.float32)).to(DEVICE)\n",
        "train_yt = torch.from_numpy(y_train.astype(np.float32)).to(DEVICE)\n",
        "\n",
        "test_xt = torch.from_numpy(X_test_s.astype(np.float32)).to(DEVICE)\n",
        "test_yt = torch.from_numpy(y_test.astype(np.float32)).to(DEVICE)"
      ],
      "metadata": {
        "id": "-9JuCxiaEa3q"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CHDataset(train_xt, train_yt)\n",
        "test_dataset = CHDataset(test_xt, test_yt)"
      ],
      "metadata": {
        "id": "9QkTwFJ4EnT-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "tDyniKMZEr9V"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adam"
      ],
      "metadata": {
        "id": "dr28So4nExyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = Adam(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "Z5Rjh7u0Eu3o"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byg9FHoDE2_-",
        "outputId": "073f45e9-2258-4736-9a66-fb4132ec249a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.089. Test acc: 0.089.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.035. Test acc: 0.022.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.016. Test acc: 0.018.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.008. Test acc: 0.018.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.010. Test acc: 0.015.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.008. Test acc: 0.015.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.007. Test acc: 0.014.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.005. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.009. Test acc: 0.010.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.009. Test acc: 0.011.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.003. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.003. Test acc: 0.005.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.010.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.007. Test acc: 0.010.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.005. Test acc: 0.008.\n",
            "Best acc train: 0.003. Best acc test: 0.003\n",
            "Training is finished!\n",
            "CPU times: user 21.6 s, sys: 3.77 s, total: 25.4 s\n",
            "Wall time: 34.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RMSprop"
      ],
      "metadata": {
        "id": "9iIKEc1VFz-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = RMSprop(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "uPX6Zb0EF3JW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md84Ec3jF6Fe",
        "outputId": "05ae665e-9202-4624-86e2-87ac68ec02b0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.100. Test acc: 0.088.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.021. Test acc: 0.013.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.010. Test acc: 0.009.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.007. Test acc: 0.008.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.008. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.007. Test acc: 0.015.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.026. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.006. Test acc: 0.012.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.008. Test acc: 0.011.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.006. Test acc: 0.010.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.006. Test acc: 0.005.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.006. Test acc: 0.012.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.006. Test acc: 0.009.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.003. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.006. Test acc: 0.008.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.004. Test acc: 0.011.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.005. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.004. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.005. Test acc: 0.005.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.011.\n",
            "Best acc train: 0.003. Best acc test: 0.005\n",
            "Training is finished!\n",
            "CPU times: user 18.5 s, sys: 3.67 s, total: 22.2 s\n",
            "Wall time: 30.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD"
      ],
      "metadata": {
        "id": "t785SDv7GEwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = CHNet().to(DEVICE)\n",
        "optimizer = SGD(net.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "pEU7jWncGGMG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_loop(train_loader, test_loader, net, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9eJhc5PGJwI",
        "outputId": "936fad53-f3a9-4f46-e73e-1c6358886250"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/241]. Loss: 0.076. Test acc: 0.088.\n",
            "Epoch [1/10]. Step [151/241]. Loss: 0.033. Test acc: 0.018.\n",
            "Epoch [1/10]. Step [241/241]. Loss: 0.013. Test acc: 0.012.\n",
            "Epoch [2/10]. Step [1/241]. Loss: 0.018. Test acc: 0.013.\n",
            "Epoch [2/10]. Step [151/241]. Loss: 0.010. Test acc: 0.010.\n",
            "Epoch [2/10]. Step [241/241]. Loss: 0.009. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [1/241]. Loss: 0.009. Test acc: 0.009.\n",
            "Epoch [3/10]. Step [151/241]. Loss: 0.009. Test acc: 0.008.\n",
            "Epoch [3/10]. Step [241/241]. Loss: 0.008. Test acc: 0.009.\n",
            "Epoch [4/10]. Step [1/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [4/10]. Step [151/241]. Loss: 0.008. Test acc: 0.008.\n",
            "Epoch [4/10]. Step [241/241]. Loss: 0.008. Test acc: 0.012.\n",
            "Epoch [5/10]. Step [1/241]. Loss: 0.007. Test acc: 0.011.\n",
            "Epoch [5/10]. Step [151/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [5/10]. Step [241/241]. Loss: 0.007. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [1/241]. Loss: 0.011. Test acc: 0.007.\n",
            "Epoch [6/10]. Step [151/241]. Loss: 0.007. Test acc: 0.008.\n",
            "Epoch [6/10]. Step [241/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [1/241]. Loss: 0.005. Test acc: 0.007.\n",
            "Epoch [7/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [7/10]. Step [241/241]. Loss: 0.007. Test acc: 0.009.\n",
            "Epoch [8/10]. Step [1/241]. Loss: 0.010. Test acc: 0.009.\n",
            "Epoch [8/10]. Step [151/241]. Loss: 0.007. Test acc: 0.006.\n",
            "Epoch [8/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [1/241]. Loss: 0.004. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [9/10]. Step [241/241]. Loss: 0.006. Test acc: 0.007.\n",
            "Epoch [10/10]. Step [1/241]. Loss: 0.008. Test acc: 0.007.\n",
            "Epoch [10/10]. Step [151/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Epoch [10/10]. Step [241/241]. Loss: 0.006. Test acc: 0.006.\n",
            "Best acc train: 0.004. Best acc test: 0.005\n",
            "Training is finished!\n",
            "CPU times: user 17.2 s, sys: 3.73 s, total: 20.9 s\n",
            "Wall time: 29.7 s\n"
          ]
        }
      ]
    }
  ]
}