{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Обучите CNN (самописная) на CIFAR-100"
      ],
      "metadata": {
        "id": "aAL2O4wPRM8D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-AuJ5JOK5RRX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "from torchsummary import summary\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
        "\n",
        "def train_valid_split(Xt):\n",
        "    X_train, X_test = train_test_split(Xt, test_size=0.05, random_state=13)\n",
        "    return X_train, X_test\n",
        "\n",
        "class MyOwnCifar(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, init_dataset, transform=None):\n",
        "        self._base_dataset = init_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self._base_dataset[idx][0]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, self._base_dataset[idx][1]\n",
        "\n",
        "trans_actions = transforms.Compose([transforms.Resize(44),\n",
        "                                    transforms.RandomCrop(32, padding=4),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "train_dataset, valid_dataset = train_valid_split(dataset)\n",
        "\n",
        "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
        "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          num_workers=3)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                          batch_size=128,\n",
        "                          shuffle=False,\n",
        "                          num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiQBVH88SGd0",
        "outputId": "1b85c1fb-e0f9-42b8-c771-afab62fa786b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device"
      ],
      "metadata": {
        "id": "jMzLT_knVpOo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.dp_three = nn.Dropout(0.2)\n",
        "        self.dp_four = nn.Dropout(0.2)\n",
        "\n",
        "        self.bn_one = torch.nn.BatchNorm2d(3)\n",
        "        self.conv_one = torch.nn.Conv2d(3, 30, 3)\n",
        "        self.bn_two = torch.nn.BatchNorm2d(30)\n",
        "        self.conv_two = torch.nn.Conv2d(30, 60, 3)\n",
        "        self.bn_three = torch.nn.BatchNorm2d(60)\n",
        "        self.conv_three = torch.nn.Conv2d(60, 120, 3)\n",
        "        self.bn_four = torch.nn.BatchNorm2d(120)\n",
        "        self.fc1 = torch.nn.Linear(480, 250)\n",
        "        self.fc2 = torch.nn.Linear(250, 150)\n",
        "        self.out = torch.nn.Linear(150, 100)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn_one(x)\n",
        "        x = self.conv_one(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.bn_two(x)\n",
        "        x = self.conv_two(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.bn_three(x)\n",
        "        x = self.conv_three(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        x = self.bn_four(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.dp_three(x)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dp_four(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        return self.out(x)\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRD5hO2jSsBl",
        "outputId": "4549b4cc-7a3d-4653-f213-9f367d2fc01e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (dp_three): Dropout(p=0.2, inplace=False)\n",
            "  (dp_four): Dropout(p=0.2, inplace=False)\n",
            "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_one): Conv2d(3, 30, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_two): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_two): Conv2d(30, 60, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_three): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_three): Conv2d(60, 120, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (bn_four): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=480, out_features=250, bias=True)\n",
            "  (fc2): Linear(in_features=250, out_features=150, bias=True)\n",
            "  (out): Linear(in_features=150, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "LoWteFPWSx1u"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(net, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH9NaZBlWog6",
        "outputId": "71242c6e-fcb5-413c-a2f4-1c07b24df7df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
            "            Conv2d-2           [-1, 30, 30, 30]             840\n",
            "       BatchNorm2d-3           [-1, 30, 15, 15]              60\n",
            "            Conv2d-4           [-1, 60, 13, 13]          16,260\n",
            "       BatchNorm2d-5             [-1, 60, 6, 6]             120\n",
            "            Conv2d-6            [-1, 120, 4, 4]          64,920\n",
            "       BatchNorm2d-7            [-1, 120, 2, 2]             240\n",
            "           Dropout-8                  [-1, 480]               0\n",
            "            Linear-9                  [-1, 250]         120,250\n",
            "          Dropout-10                  [-1, 250]               0\n",
            "           Linear-11                  [-1, 150]          37,650\n",
            "           Linear-12                  [-1, 100]          15,100\n",
            "================================================================\n",
            "Total params: 255,446\n",
            "Trainable params: 255,446\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.40\n",
            "Params size (MB): 0.97\n",
            "Estimated Total Size (MB): 1.39\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(3)):\n",
        "    net.train()\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    net.eval()\n",
        "    loss_accumed = 0\n",
        "    for X, y in valid_loader:\n",
        "        output = net(X)\n",
        "        loss = criterion(output, y)\n",
        "        loss_accumed += loss\n",
        "    print(\"Epoch {} valid_loss {}\".format(epoch, loss_accumed))\n",
        "    net.train()\n",
        "\n",
        "print('\\nTraining is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMiJdv1KTSdb",
        "outputId": "858dbf75-5c28-4552-f1bd-f0f311b73a68"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [01:27<02:55, 87.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 valid_loss 67.17462158203125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [02:55<01:27, 87.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 valid_loss 68.25067901611328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [04:22<00:00, 87.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 valid_loss 67.94888305664062\n",
            "\n",
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}